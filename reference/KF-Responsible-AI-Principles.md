Responsible AI Principles for Advancing a More Equitable Innovation Future

Artificial intelligence will shape education, labor, the economy, civil and human rights, and the environment for decades. How AI is designed, developed, and deployed today will determine who benefits tomorrow.

Responsible AI must advance racial, economic, and environmental justice.

Principles are informed by research across AI ethics, technology justice, civil rights, and human rights disciplines.

1. Utilize a Sociotechnical Framework

AI systems should be understood as part of broader social, political, and economic systems. Developers and funders must clearly define the problem being addressed and assess whether AI is an appropriate solution.

2. Incorporate Prosocial Design Principles

AI design should prioritize societal benefit rather than profit alone. Impacted communities should be involved throughout the lifecycle of AI systems, from conception to deployment and evaluation.

3. Support AI Initiatives That Shift Power

Responsible AI should redistribute power by supporting inclusive business models, alternative ownership structures, and compensation systems that value collective benefit.

4. Promote Critical AI Literacy and Education

People must be empowered to understand, question, and influence AI systems. This includes expanding access to computing education and advancing critical AI literacy for workers, consumers, and advocates.

5. Build Collective Governance and Accountability

Responsible AI requires governance structures that enable democratic oversight, transparency, whistleblowing, journalism, and regulatory enforcement.

AI accountability must be shared across institutions, not left solely to private actors.
